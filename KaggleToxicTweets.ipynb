{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KaggleToxicTweets.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/idontcalculate/kaggletweets/blob/main/KaggleToxicTweets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfuRmHKrhR2a"
      },
      "source": [
        "Aim is to classificate tweets from Kaggle dataset in 6 categories (labels) and to make functional network that can sort tweets and make prediction with test dataset. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiH1Inlrg7j6"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0XuvX9-g8Be"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfkNEAhegu-t",
        "outputId": "e85020f1-1925-4840-e10c-40d895ebf63f"
      },
      "source": [
        "#check for GPU\n",
        "!nvidia-smi -L"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla V100-SXM2-16GB (UUID: GPU-55722894-32f6-1db4-f131-27e1d7116c67)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8ltNj4S1OrM"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGyvm8s1wzUw",
        "outputId": "c04081b2-5184-4c6d-9908-187e5c639132"
      },
      "source": [
        "!pip install kaggle "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2020.12.5)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxBsWEb0yuSX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6d04e78-4254-4a78-d5cc-71c251296fe8"
      },
      "source": [
        "!mv /content/kaggle.json /root/.kaggle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mv: cannot stat '/content/kaggle.json': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfF0tFG7xc_B",
        "outputId": "16c9ff71-dba0-4239-b0fa-a8cd348a2e0f"
      },
      "source": [
        "!kaggle competitions download -c jigsaw-toxic-comment-classification-challenge"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "sample_submission.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "test.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "train.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "test_labels.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtI_8jLBilZt",
        "outputId": "79a33b6f-bc8a-4748-93b1-2af940bca1c7"
      },
      "source": [
        "# Download helper functions script\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-08 12:55:21--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py.1’\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-06-08 12:55:21 (90.8 MB/s) - ‘helper_functions.py.1’ saved [10246/10246]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ua6rFCDqxB9h",
        "outputId": "a78659a9-a18e-4a20-f132-32f4648b3ca4"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Jun  8 13:16:18 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    24W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJgow1Xiiv3A"
      },
      "source": [
        "# Import series of helper functions for the notebook\n",
        "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
      ],
      "execution_count": 237,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9M0LppY7esx",
        "outputId": "a356fe3e-f9b1-41fa-bf32-3c7f8ef692f6"
      },
      "source": [
        "!unzip /content/test_labels.csv.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/test_labels.csv.zip\n",
            "replace test_labels.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPkmBkHI61Z6"
      },
      "source": [
        "!unzip /content/train.csv.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upFym3cpu9Xa"
      },
      "source": [
        "!unzip /content/test.csv.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEeCkghS2e4T"
      },
      "source": [
        "import pandas as pd \n",
        "train_df = pd.read_csv('/content/train.csv.zip')\n",
        "test_df  = pd.read_csv('/content/test.csv.zip')"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5Dxy4pd8AiK"
      },
      "source": [
        "test_labels = pd.read_csv('/content/test_labels.csv.zip')"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrXHfpVb_sU9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3a0f401-1e0d-4872-f92a-3bb5e8727893"
      },
      "source": [
        "len(train_df), len(test_df)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(159571, 153164)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JydKgU1rNgmd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2d88bc7-a2b3-4e41-a832-8f340bea3381"
      },
      "source": [
        "# How many samples total?\n",
        "print(f\"Total training samples: {len(train_df)}\")\n",
        "print(f\"Total test samples: {len(test_df)}\")\n",
        "print(f\"Total samples: {len(train_df) + len(test_df)}\")"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total training samples: 159571\n",
            "Total test samples: 153164\n",
            "Total samples: 312735\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxivKnye2NIq"
      },
      "source": [
        "def create_text_label(dataframe):\n",
        "  texts = dataframe.comment_text.to_numpy()\n",
        "  labels = dataframe.drop(columns =['id','comment_text']).to_numpy()\n",
        "  return texts,labels\n"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwuXAjLx0J38"
      },
      "source": [
        "x_train,y_train = create_text_label(train_df)"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKKoTDdO24qS"
      },
      "source": [
        "x_test,y_test = create_text_label(test_df)"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2LOAnKX0cUv"
      },
      "source": [
        "y_test = test_labels.drop('id',axis = 1).to_numpy()"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XA_1R0UN-0xF",
        "outputId": "0e801e5a-c2f9-415e-8b72-a08f89bb2757"
      },
      "source": [
        "x_train[:10],y_train[:10]"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([\"Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\",\n",
              "        \"D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)\",\n",
              "        \"Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.\",\n",
              "        '\"\\nMore\\nI can\\'t make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It\\'s listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  \"',\n",
              "        \"You, sir, are my hero. Any chance you remember what page that's on?\",\n",
              "        '\"\\n\\nCongratulations from me as well, use the tools well. \\xa0· talk \"',\n",
              "        'COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK',\n",
              "        \"Your vandalism to the Matt Shirvington article has been reverted.  Please don't do it again, or you will be banned.\",\n",
              "        \"Sorry if the word 'nonsense' was offensive to you. Anyway, I'm not intending to write anything in the article(wow they would jump on me for vandalism), I'm merely requesting that it be more encyclopedic so one can use it for school as a reference. I have been to the selective breeding page but it's almost a stub. It points to 'animal breeding' which is a short messy article that gives you no info. There must be someone around with expertise in eugenics? 93.161.107.169\",\n",
              "        'alignment on this subject and which are contrary to those of DuLithgow'],\n",
              "       dtype=object), array([[0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [1, 1, 1, 0, 1, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coqIZyRd-0vC",
        "outputId": "e7790028-27f7-4653-991d-65d26ab31760"
      },
      "source": [
        "x_test[:10],y_test[:10]"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([\"Yo bitch Ja Rule is more succesful then you'll ever be whats up with you and hating you sad mofuckas...i should bitch slap ur pethedic white faces and get you to kiss my ass you guys sicken me. Ja rule is about pride in da music man. dont diss that shit on him. and nothin is wrong bein like tupac he was a brother too...fuckin white boys get things right next time.,\",\n",
              "        '== From RfC == \\n\\n The title is fine as it is, IMO.',\n",
              "        '\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lapland —  /  \"',\n",
              "        \":If you have a look back at the source, the information I updated was the correct form. I can only guess the source hadn't updated. I shall update the information once again but thank you for your message.\",\n",
              "        \"I don't anonymously edit articles at all.\",\n",
              "        'Thank you for understanding. I think very highly of you and would not revert without discussion.',\n",
              "        'Please do not add nonsense to Wikipedia. Such edits are considered vandalism and quickly undone. If you would like to experiment, please use the sandbox instead. Thank you.   -',\n",
              "        ':Dear god this site is horrible.',\n",
              "        '\" \\n Only a fool can believe in such numbers. \\n The correct number lies between 10 000 to 15 000. \\n Ponder the numbers carefully.  \\n\\n This error will persist for a long time as it continues to reproduce... The latest reproduction I know is from ENCYCLOPÆDIA BRITANNICA ALMANAC 2008 wich states \\n Magnittude: 8.7 (fair enough) \\n victims: 70 000 (today 10 000 to 15 000 is not \"\"a lot\"\" so I guess people just come out with a number that impresses enough, I don\\'t know. But I know this: it\\'s just a shameless lucky number that they throw in the air. \\n GC \\n\\n \"',\n",
              "        \"== Double Redirects == \\n\\n When fixing double redirects, don't just blank the outer one, you need edit it to point it to the final target, unless you think it's inappropriate, in which case, it needs to be nominated at WP:RfD\"],\n",
              "       dtype=object), array([[-1, -1, -1, -1, -1, -1],\n",
              "        [-1, -1, -1, -1, -1, -1],\n",
              "        [-1, -1, -1, -1, -1, -1],\n",
              "        [-1, -1, -1, -1, -1, -1],\n",
              "        [-1, -1, -1, -1, -1, -1],\n",
              "        [ 0,  0,  0,  0,  0,  0],\n",
              "        [-1, -1, -1, -1, -1, -1],\n",
              "        [ 0,  0,  0,  0,  0,  0],\n",
              "        [-1, -1, -1, -1, -1, -1],\n",
              "        [-1, -1, -1, -1, -1, -1]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "YJmn1zFn-0sr",
        "outputId": "3371f7f1-8fac-4fd9-c1cf-9609417027ec"
      },
      "source": [
        "y_train.head()"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
              "0      0             0        0       0       0              0\n",
              "1      0             0        0       0       0              0\n",
              "2      0             0        0       0       0              0\n",
              "3      0             0        0       0       0              0\n",
              "4      0             0        0       0       0              0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4DV7s8s0hSl",
        "outputId": "5f2360e1-1095-4c4d-8ded-00ccb44fc8e1"
      },
      "source": [
        "len(x_train)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "159571"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95o5LHPV0hH7",
        "outputId": "20683607-ac77-49d1-f670-57cb94f5f537"
      },
      "source": [
        "len(train_data_text[0])"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "264"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1St20qCPNID"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "# Use the default TextVectorization\n",
        "text_vectorizer = TextVectorization(max_tokens=None, # how many words in the vocabulary (all of the different words in your text)\n",
        "                                    standardize=\"lower_and_strip_punctuation\", # how to process text\n",
        "                                    split=\"whitespace\", # how to split tokens\n",
        "                                    ngrams=None, # create groups of n-words?\n",
        "                                    output_mode=\"int\", # how to map tokens to numbers\n",
        "                                    output_sequence_length=None, # how long should the output sequence of tokens be?\n",
        "                                    pad_to_max_tokens=True)"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0ErgFjkPjzF"
      },
      "source": [
        "For max_tokens (the number of words in the vocabulary), multiples of 10,000 (10,000, 20,000, 30,000) or the exact number of unique words in your text (e.g. 32,179) are common values.\n",
        "\n",
        "For our use case, we'll use 10,000.\n",
        "\n",
        "And for the output_sequence_length we'll use the average number of tokens per Tweet in the training set. But first, we'll need to find it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaweJeZQPUd_"
      },
      "source": [
        "# Setup text vectorization variables\n",
        "max_vocab_length = 10000 # max number of words to have in our vocabulary\n",
        "max_length = 15 # max length our sequences will be (e.g. how many words from a Tweet does our model see?)\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
        "                                    output_mode=\"int\",\n",
        "                                    output_sequence_length=max_length)"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpT72YM2QWup"
      },
      "source": [
        "putting dataframe into data_sentences, and then making and array, before vectorizing. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBKla3FexYRc"
      },
      "source": [
        "text_vectorizer.adapt(x_train)\n",
        "# x_test = text_vectorizer.adapt(np.array(x_test))\n"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7jnc06eWA1B"
      },
      "source": [
        "text_vectorizer.adapt(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G41-Me-r1tNy",
        "outputId": "8df2e860-6f88-45db-f3d7-2b9e58f3796d"
      },
      "source": [
        "text_vectorizer(x_train[:1])"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[ 645,   76,    2,  122,  127,  172,   29,  636, 4604,    1, 1282,\n",
              "          83,  313,   53, 2076]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYz9-uN090Mj",
        "outputId": "bf2759c6-3ac3-44cf-cfd9-9f014ac710a1"
      },
      "source": [
        "sample_scentence = 'this is the sample scentence'\n",
        "text_vectorizer([sample_scentence])"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[  14,    9,    2, 4705,    1,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffPPd-fw8zBH"
      },
      "source": [
        "text_vocab = text_vectorizer.get_vocabulary()"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l82p1nxX2Apf",
        "outputId": "c1670107-fc15-46a2-8c84-71878efb6759"
      },
      "source": [
        "text_vectorizer(x_test)"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(153164, 15), dtype=int64, numpy=\n",
              "array([[2661,  762,    1, ...,   81,   22,    7],\n",
              "       [  31, 1246,    2, ...,    0,    0,    0],\n",
              "       [ 107,    1,    1, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [   1, 1212,    8, ...,    8,   99, 2591],\n",
              "       [  50,    4,    2, ...,    4, 1384,  357],\n",
              "       [ 168,  226,   21, ...,   23,    7,   69]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bf3jbRrd6-tq",
        "outputId": "f29037f3-db0e-43e0-b4c0-1f806ed3abbd"
      },
      "source": [
        "# Get the unique words in the vocabulary\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "top_5_words = words_in_vocab[:5] # most common tokens (notice the [UNK] token for \"unknown\" words)\n",
        "bottom_5_words = words_in_vocab[-5:] # least common tokens\n",
        "print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n",
        "print(f\"Top 5 most common words: {top_5_words}\") \n",
        "print(f\"Bottom 5 least common words: {bottom_5_words}\")"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words in vocab: 10000\n",
            "Top 5 most common words: ['', '[UNK]', 'the', 'to', 'of']\n",
            "Bottom 5 least common words: ['domination', 'divorced', 'distorting', 'direktor', 'dildo']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpGjSPNrJ3NB"
      },
      "source": [
        "activating embedding layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pd4Ir7TdJ6tf",
        "outputId": "15a14f0d-1461-491d-e44f-92e1ac27cff5"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding = layers.Embedding(input_dim=max_vocab_length, # set input shape\n",
        "                             output_dim=128, # set size of embedding vector\n",
        "                             embeddings_initializer=\"uniform\", # default, intialize randomly\n",
        "                             input_length=max_length) # how long is each input\n",
        "\n",
        "embedding"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.layers.embeddings.Embedding at 0x7f96d7937b90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08E0zKx9KFU9",
        "outputId": "80654eb0-93e0-4f89-f04e-3f4797523cb6"
      },
      "source": [
        "# Get a random sentence from training set\n",
        "import random\n",
        "random_sentence = random.choice(x_train)\n",
        "print(f\"Original text:\\n{random_sentence}\\\n",
        "      \\n\\nEmbedded version:\")\n",
        "\n",
        "# Embed the random sentence (turn it into numerical representation)\n",
        "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
        "sample_embed"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original text:\n",
            "\"\n",
            "\n",
            " hi \n",
            "\n",
            "yes I was in the process of doing that.  One thing, however.  Are you familiar with the distinction between \"\"pages for deletion\"\" and \"\"votes for deletion?\"\"  What is going on there? \"      \n",
            "\n",
            "Embedded version:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[ 0.03662921,  0.04177663,  0.034984  , ...,  0.01993462,\n",
              "         -0.01815165, -0.0136642 ],\n",
              "        [-0.00978785,  0.02481626, -0.01908884, ...,  0.01024635,\n",
              "          0.03374508, -0.02607433],\n",
              "        [-0.00246595, -0.00769802, -0.04085737, ...,  0.00209464,\n",
              "          0.04397613,  0.02414354],\n",
              "        ...,\n",
              "        [ 0.03883507,  0.01510395, -0.03064976, ...,  0.02610817,\n",
              "          0.0307348 ,  0.02778542],\n",
              "        [ 0.04470099,  0.01998186,  0.01321849, ..., -0.00013406,\n",
              "         -0.02289292, -0.00056386],\n",
              "        [ 0.04080817, -0.00557964,  0.0499302 , ...,  0.01024337,\n",
              "         -0.00065855,  0.03001625]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mh2onoroK4C2",
        "outputId": "d1bf20ff-aeb6-42c4-b6d0-a437cf3df57d"
      },
      "source": [
        "#single token's embedding\n",
        "sample_embed[0][0]"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              "array([ 3.66292112e-02,  4.17766310e-02,  3.49840038e-02, -9.54092667e-03,\n",
              "       -2.20099576e-02,  5.31911850e-04,  5.92816621e-04, -4.17434089e-02,\n",
              "       -7.10426643e-03, -3.06384694e-02, -5.44846058e-03,  2.18055397e-03,\n",
              "       -1.42780542e-02, -2.50807405e-02,  3.74308117e-02,  3.32780741e-02,\n",
              "        2.45540254e-02, -1.90954208e-02,  1.25467218e-02,  4.64549400e-02,\n",
              "        4.48097251e-02, -3.12320720e-02, -5.04038483e-03,  1.83659457e-02,\n",
              "       -3.25421244e-02, -4.24530506e-02,  4.98774983e-02, -7.39242882e-03,\n",
              "       -4.31500338e-02, -4.92305420e-02,  1.94595493e-02,  5.03449515e-03,\n",
              "        4.94187139e-02, -2.03878041e-02,  4.78857197e-02, -3.11423671e-02,\n",
              "       -7.19553232e-03, -9.22361761e-03,  4.84148748e-02,  1.89566351e-02,\n",
              "       -1.99457537e-02, -4.05566767e-03, -7.99406320e-04,  1.53911598e-02,\n",
              "       -2.11711656e-02, -3.50661166e-02,  6.52503967e-03, -1.40803829e-02,\n",
              "       -2.25584861e-02, -3.46636176e-02,  4.11222838e-02,  8.99727270e-03,\n",
              "       -2.21306812e-02, -9.81222466e-03, -2.51394268e-02, -2.81945001e-02,\n",
              "       -2.60822661e-02,  4.59413417e-02,  1.53377093e-02, -3.45636979e-02,\n",
              "        2.05529667e-02,  3.49369161e-02, -4.36620116e-02, -4.81076241e-02,\n",
              "        4.33446057e-02, -3.61556895e-02, -4.60688248e-02,  3.59553732e-02,\n",
              "        3.29493359e-03,  7.56354257e-03, -4.14269194e-02, -8.07263702e-03,\n",
              "        2.65651941e-03, -2.24330183e-02,  4.61236872e-02, -2.02488154e-04,\n",
              "       -6.92477077e-03, -2.51786709e-02,  2.85771526e-02, -2.56190784e-02,\n",
              "       -2.81965267e-02, -7.99546391e-03, -4.63029854e-02, -1.38097182e-02,\n",
              "        2.82885768e-02, -1.30007416e-03, -1.52294710e-03, -1.37605667e-02,\n",
              "       -4.04596813e-02, -3.79378796e-02, -1.18084997e-03,  4.26653512e-02,\n",
              "       -8.78050178e-03,  3.72128747e-02,  4.88672592e-02,  4.65173386e-02,\n",
              "        3.23901065e-02,  1.58332624e-02,  3.09917070e-02,  2.10035481e-02,\n",
              "       -1.97722204e-02,  7.23048300e-03,  2.49245502e-02,  4.06004526e-02,\n",
              "       -4.40066718e-02,  2.91442014e-02,  2.81144865e-02,  7.52330944e-03,\n",
              "        1.12002604e-02,  8.39307904e-06, -1.76304579e-03, -2.07856055e-02,\n",
              "        2.26540230e-02,  2.29427926e-02, -2.61566173e-02,  4.09756564e-02,\n",
              "        3.73774879e-02, -1.65927410e-03,  2.73606926e-03, -3.46216448e-02,\n",
              "        2.96471231e-02, -3.52514163e-02,  1.09907165e-02,  2.48541571e-02,\n",
              "       -3.33091989e-02,  1.99346207e-02, -1.81516521e-02, -1.36641972e-02],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5I9E5fBPY6j"
      },
      "source": [
        "creating the basseline model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "es9j4W3NQmlc",
        "outputId": "6d2ec4fa-6e76-417b-f2e4-c643f946f807"
      },
      "source": [
        "x_train.shape, y_train.shape"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((159571,), (159571, 6))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prBZeTTnl6Jz"
      },
      "source": [
        "#SAVE DIR AND CALLBACKS\n",
        "\n",
        "from helper_functions import create_tensorboard_callback\n",
        "\n",
        "#create dir to save tensorboard logs\n",
        "SAVE_DIR = \"model_logs\"\n",
        "\n",
        "#print(type(SAVE_DIR))"
      ],
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfpzkL2OOeuL",
        "outputId": "13bd2932-0a74-41aa-fd85-61e06fe0a3d4"
      },
      "source": [
        "# Create LSTM model\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "print(x.shape)\n",
        "# x = layers.LSTM(64, return_sequences=True)(x) # return vector for each word in the Tweet (you can stack RNN cells as long as return_sequences=True)\n",
        "x = layers.LSTM(64)(x) # return vector for whole sequence\n",
        "print(x.shape)\n",
        "# x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer on top of output of LSTM cell\n",
        "outputs = layers.Dense(6, activation=\"softmax\")(x)\n",
        "model_1 = tf.keras.Model(inputs, outputs, name=\"LTSM_kaggle\")"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 15, 128)\n",
            "(None, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KojcK6Z8WsQO"
      },
      "source": [
        "# Compile model\n",
        "model_1.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfPcUKefaEcK",
        "outputId": "fb72e146-2c29-4414-a51e-6a8bb1babb12"
      },
      "source": [
        "# F model\n",
        "model_1_history = model_1.fit(x_train,\n",
        "                              y_train,\n",
        "                              epochs=5,\n",
        "                              validation_data=(x_test, y_test),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \n",
        "                                                                     callbacks=[create_tensorboard_callback(SAVE_DIR, \n",
        "                                                                     \"LSTM_kaggle\")])"
      ],
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/LTSM_kaggle/20210608-170743\n",
            "Epoch 1/5\n",
            "4987/4987 [==============================] - 111s 22ms/step - loss: 0.3785 - accuracy: 0.9377 - val_loss: -6.5668 - val_accuracy: 0.8452\n",
            "Epoch 2/5\n",
            "4987/4987 [==============================] - 104s 21ms/step - loss: 0.3619 - accuracy: 0.9346 - val_loss: -6.5858 - val_accuracy: 0.8366\n",
            "Epoch 3/5\n",
            "4987/4987 [==============================] - 104s 21ms/step - loss: 0.3490 - accuracy: 0.9336 - val_loss: -6.6129 - val_accuracy: 0.8241\n",
            "Epoch 4/5\n",
            "4987/4987 [==============================] - 106s 21ms/step - loss: 0.3390 - accuracy: 0.9331 - val_loss: -6.6006 - val_accuracy: 0.8313\n",
            "Epoch 5/5\n",
            "4987/4987 [==============================] - 104s 21ms/step - loss: 0.3322 - accuracy: 0.9352 - val_loss: -6.6302 - val_accuracy: 0.8543\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFUOeGHucYMZ",
        "outputId": "f5833363-6853-415d-a5fe-40b3eec82aaa"
      },
      "source": [
        "!pip install tensorboard"
      ],
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (2.5.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.8.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (57.0.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.34.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.4.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.6.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.12.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.19.5)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.30.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.36.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.12.0)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio>=1.24.3->tensorboard) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard) (4.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (0.2.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard) (3.7.4.3)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y63R8KgQpuw5",
        "outputId": "3ddb9be6-6ad1-4fab-9e65-d723cce02e40"
      },
      "source": [
        "!tensorboard dev upload --logdir ./model_logs/LTSM_kaggle --one_shot"
      ],
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-06-08 17:42:16.276228: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Data for the \"text\" plugin is now uploaded to TensorBoard.dev! Note that uploaded data is public. If you do not want to upload data for this plugin, use the \"--plugins\" command line argument.\n",
            "\n",
            "New experiment created. View your TensorBoard at: https://tensorboard.dev/experiment/1IOglpC4Sky3KEvH3nuBSA/\n",
            "\n",
            "\u001b[1m[2021-06-08T17:42:17]\u001b[0m Started scanning logdir.\n",
            "\u001b[1m[2021-06-08T17:42:18]\u001b[0m Total uploaded: 30 scalars, 0 tensors, 1 binary objects (255.8 kB)\n",
            "\u001b[1m[2021-06-08T17:42:18]\u001b[0m Done scanning logdir.\n",
            "\n",
            "\n",
            "Done. View your TensorBoard at https://tensorboard.dev/experiment/1IOglpC4Sky3KEvH3nuBSA/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "sVhMGwSqsD4Y",
        "outputId": "10f12f7a-8f48-4221-b614-28a71310540f"
      },
      "source": [
        "SAVE_DIR"
      ],
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'model_logs'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TF3gMEK1L9H"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "# Use the default TextVectorization\n",
        "text_vectorizer = TextVectorization(max_tokens=None, # how many words in the vocabulary (all of the different words in your text)\n",
        "                                    standardize=\"lower_and_strip_punctuation\", # how to process text\n",
        "                                    split=\"whitespace\", # how to split tokens\n",
        "                                    ngrams=None, # create groups of n-words?\n",
        "                                    output_mode=\"int\", # how to map tokens to numbers\n",
        "                                    output_sequence_length=None, # how long should the output sequence of tokens be?\n",
        "                                    pad_to_max_tokens=True)"
      ],
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMKwl0Lf0-ax"
      },
      "source": [
        "# Setup text vectorization variables\n",
        "max_vocab_length = 10000 # max number of words to have in our vocabulary\n",
        "max_length = 15 # max length our sequences will be (e.g. how many words from a Tweet does our model see?)\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
        "                                    output_mode=\"int\",\n",
        "                                    output_sequence_length=max_length,\n",
        "                                    ngrams=2)"
      ],
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYCzo0j0txr4",
        "outputId": "e44fb1fe-7404-4669-9704-307ceee21ecc"
      },
      "source": [
        "#crate model 2 for kaggle\n",
        "\n",
        "# Create another LTSM \n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "print(x.shape)\n",
        "# x = layers.LSTM(64, return_sequences=True)(x) # return vector for each word in the Tweet (you can stack RNN cells as long as return_sequences=True)\n",
        "x = layers.LSTM(64)(x) # return vector for whole sequence\n",
        "print(x.shape)\n",
        "# x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer on top of output of LSTM cell\n",
        "outputs = layers.Dense(6, activation=\"softmax\")(x)\n",
        "model_2 = tf.keras.Model(inputs, outputs, name=\"LTSM_kaggle_2\")\n"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 15, 128)\n",
            "(None, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MU5iKe6zNLe"
      },
      "source": [
        "# Compile model\n",
        "model_2.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QX3tUynp3QnT",
        "outputId": "79771130-4139-40f8-ea78-e8eec6e25bdf"
      },
      "source": [
        "#fit the model\n",
        "model_2_history = model_2.fit(x_train,\n",
        "                              y_train,\n",
        "                              epochs=10,\n",
        "                              validation_data=(x_test, y_test),\n",
        "                              callbacks = [create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                       \"LTSM_kaggle_2\")])"
      ],
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/LTSM_kaggle_2/20210608-182429\n",
            "Epoch 1/10\n",
            "4987/4987 [==============================] - 114s 23ms/step - loss: 0.3360 - accuracy: 0.9921 - val_loss: -6.4351 - val_accuracy: 0.9990\n",
            "Epoch 2/10\n",
            "4987/4987 [==============================] - 111s 22ms/step - loss: 0.3305 - accuracy: 0.9942 - val_loss: -6.5016 - val_accuracy: 0.9990\n",
            "Epoch 3/10\n",
            "4987/4987 [==============================] - 112s 22ms/step - loss: 0.3268 - accuracy: 0.9942 - val_loss: -6.5434 - val_accuracy: 0.9990\n",
            "Epoch 4/10\n",
            "4987/4987 [==============================] - 131s 26ms/step - loss: 0.3240 - accuracy: 0.9942 - val_loss: -6.6141 - val_accuracy: 0.9990\n",
            "Epoch 5/10\n",
            "4987/4987 [==============================] - 112s 22ms/step - loss: 0.3218 - accuracy: 0.9942 - val_loss: -6.6888 - val_accuracy: 0.9990\n",
            "Epoch 6/10\n",
            "4987/4987 [==============================] - 131s 26ms/step - loss: 0.3200 - accuracy: 0.9942 - val_loss: -6.7121 - val_accuracy: 0.9990\n",
            "Epoch 7/10\n",
            "4987/4987 [==============================] - 111s 22ms/step - loss: 0.3188 - accuracy: 0.9942 - val_loss: -6.7647 - val_accuracy: 0.9990\n",
            "Epoch 8/10\n",
            "4987/4987 [==============================] - 112s 22ms/step - loss: 0.3178 - accuracy: 0.9942 - val_loss: -6.7421 - val_accuracy: 0.9990\n",
            "Epoch 9/10\n",
            "4987/4987 [==============================] - 111s 22ms/step - loss: 0.3171 - accuracy: 0.9942 - val_loss: -6.7885 - val_accuracy: 0.9990\n",
            "Epoch 10/10\n",
            "4987/4987 [==============================] - 111s 22ms/step - loss: 0.3165 - accuracy: 0.9942 - val_loss: -6.8439 - val_accuracy: 0.9990\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1xhrXIm--gS",
        "outputId": "c62d8909-819c-4a46-8ce7-55e98a03c0cd"
      },
      "source": [
        "#check the results\n",
        "model_2.evaluate(x_test, y_test)"
      ],
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4787/4787 [==============================] - 25s 5ms/step - loss: -6.8439 - accuracy: 0.9990\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-6.843910217285156, 0.9990010857582092]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 231
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJll-WPg_kFQ",
        "outputId": "cae9c457-21cd-4ca4-fe13-5881b6408306"
      },
      "source": [
        "#predictions\n",
        "model_2_pred_probs = model_2.predict(x_test)\n",
        "model_2_pred_probs.shape"
      ],
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(153164, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 232
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4mHOjj6ABb_",
        "outputId": "93be1045-75e7-48f8-fc36-b00c6b3f92a0"
      },
      "source": [
        "model_2_pred_probs[:10]"
      ],
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.32410717, 0.09550231, 0.23191188, 0.04867075, 0.21802068,\n",
              "        0.08178723],\n",
              "       [0.32410717, 0.09550231, 0.23191188, 0.04867075, 0.21802068,\n",
              "        0.08178723],\n",
              "       [0.32410717, 0.09550231, 0.23191188, 0.04867075, 0.21802068,\n",
              "        0.08178723],\n",
              "       [0.32410717, 0.09550231, 0.23191188, 0.04867075, 0.21802068,\n",
              "        0.08178723],\n",
              "       [0.32410717, 0.09550231, 0.23191188, 0.04867075, 0.21802068,\n",
              "        0.08178723],\n",
              "       [0.32410717, 0.09550231, 0.23191188, 0.04867075, 0.21802068,\n",
              "        0.08178723],\n",
              "       [0.32410717, 0.09550231, 0.23191188, 0.04867075, 0.21802068,\n",
              "        0.08178723],\n",
              "       [0.32410717, 0.09550231, 0.23191188, 0.04867075, 0.21802068,\n",
              "        0.08178723],\n",
              "       [0.32410717, 0.09550231, 0.23191188, 0.04867075, 0.21802068,\n",
              "        0.08178723],\n",
              "       [0.32410717, 0.09550231, 0.23191188, 0.04867075, 0.21802068,\n",
              "        0.08178723]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 233
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPGYbTQCAiU_",
        "outputId": "eee0549e-2609-4e38-b727-732962830c94"
      },
      "source": [
        "# Turn prediction probabilities into single-dimension tensor of floats\n",
        "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs)) # squeeze removes single dimensions\n",
        "model_2_preds[:50]"
      ],
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50, 6), dtype=float32, numpy=\n",
              "array([[0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 235
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhZBYMQwMkZF"
      },
      "source": [
        "results should be in panda dataframe in order to submit. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hhsjrjf3DOBX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}